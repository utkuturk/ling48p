# Good Enough by Ferreria and Patson

- the idea is to challenge the overarching thought that human parser tries to understand everything.
- people do not really required to do some articulate work behind the scenes, they just need to nod or some motor action, nothing fancy.
- the system might not even resolve the ambiguities
- and the experiment may bias subjects towards trying even harder.
- system may even ignore some elements and not compute specific structure.

#### __Ferreria Findings in 2002__
1. people often obtain shallow understanding of a sentence's meaning.
2. people sometimes outright misunderstand sentences.

_How many of each type of animal did Moses take on the ark?_ (Erickson and Matteson 1981)
- Most people overlook the anomaly in the question 'Where should the authorities bury the survivors?' 
- People understand the sentence __well enough__ to realize what they are asked about, but __not depply enough__ to appreciate the difference between the details.
- __There are lots of evidence for incomplete and shallow representation__
#### __Frazier 1999__ 
- Mary and John saved $100
  - each or together? They do not specify the information, they do when there is enough context for interpretation

#### __Sanford and Sturt 2002__ underspecification > computational advantages 

### Ferreria _Again_ 2001
- We look at the garden sentences and when the misunderstood but do we really  ultimately understood correctly.
- the form of the question may lead the high percentage of incorrect _yes_ responses, it might have reinstated the original misparse.
#### Patson 2006
- participants were given similar sentences and then asked to recall them immediately or after a delay. No yes\no questions.

#### Ferreria 2003
- the dog ws bitten by the man: college students mostly give the wrong answer even if the sentence is completely grammatical.

> Paper will first deal with the effects of local coherence. Then, ERP and heuristics. Lastly, mechanism that helps people in non-error-free utterances, as they expect spoken discourse to be.

### effects of local coherence
- heuristic generates challenges the parser when it tries to integrate the other words in the sentence.
- Local meaning disrupts the global interpretation
- local coherence effects supports the Sausage Machine, which assumes PPP creates local parses, which are put together by SSS.
- Ferreria and Fodor also found the effects of __mere local coherence__.
  - Subjects are asked to read and judge ungrammatical sentences.
  - The ungrammatical sentences were incorrectly judged to be grammatical on about one third of the trials, which was much higher than for ordinary ungrammatical sentences.
    - They mostly go back to verb fixed and the NP following, so they know which one of the local sequences interfere with the global grammaticity.
    - This type of sentences and trials shows that system works by cobbling together local analyses, and thus, has difficulty when local analyses cannot be integrated into global structure.
    - Also, ERP recordings supports the heuristic use.
      - Even though the problem was semantic, not N400, but P600 _syntactic revision index_ was observed.
      - It is because the parser automatically ignored the sentence and went for the possible meaning, Ignoreing _a fax shot a poacher_, understanding _a poacher shot a fox_.
  - Also, Tabor found that even locally plausible sequences interfere with global processing.
- So, these all mean that people tend to misinterpret implausible sentences so they convey sensible propositions.
  - an important reason why this is so:
    - people sometimes dont say what they mean,
    - they make mistakes during production
  - If comprehension system was not forgiving, we would not be able to make sense what is being told to us most of the time.
  - but it does not always normalize sentences. so there must be a trigger.
    - This trigger can be the content.
- System computes a sensible meaning, and then tries to reconcile it with the sentence's form.
  - If the two conflict, then reconstruction happens.
    - Either go with the new one, or make sense of the old one as an unexpected idea.
- We also exclude disfluencies, fillers, corrections and such.
  - but this stuff perfect for GE.
  - when a garden path sentence is seperated around the danger zone, it even gets harder.
    - the further the head from the disambiguator, the longer the parser has been committed to the wrong analysis of the ambigous phrase.
    - And, this is the same for fillers.
      - fillers allow the parser the strengthen the syntactic and semantic analysis it has built up to that point.
      - cuing function: when people hear a filler, whichever be, the assume following phrase would end up being more complex.
  - Correction, too, has been examined.
    - reparandum: the error
    - repair: where the reparandum is corrected. _Turn left,_ I mean __turn right__ at the light.
    - the thing is that comprehension system __DOES NOT__ completely erase the reparandum from the representation.
  - __BUT THESE STUDIES ARE OFFLINE__ BAM.
    - But Bailey remedied this flaw with __visual world paradigm__ to explore how corrections are done incrementally.
      - Bailey found out that looks to the reparandum persisted long past the repair part. 
      - __REPARANDUM INDEED LINGERS.__
- People are not logical, perfect, effectively reasoning creatures. And they use heuristics.

## Return the the model of parsing like garden path minimalism
That is, the minimal attachment principle states that the parser should build the _simplest_ structure it can, and __revise it only if necessary.__
- Revise it as a last resort, not because it could be better.
  - if it is not broken, leave it be.
- this approach is better for real world situations.
  - understanding and revising takes time, and it is not economical during a dialog.

Utku Turk, Apr 7, '18